
## **ğŸ“ README.md (Atriva AI API)**

```md
# Atriva AI API with RKNN for Rockchip ğŸš€

This is a FastAPI-based AI API that leverages **RKNN (Rockchip Neural Network)** for optimized deep learning inference on Rockchip hardware.  
It provides a RESTful interface for running AI models, such as object detection and image classification on RK3588 platform.

## **ğŸ“‚ Project Structure**
```plaintext
atriva-ai-rockchip/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ routes.py         # API route definitions
â”‚   â”œâ”€â”€ services.py       # AI model processing logic
â”‚   â”œâ”€â”€ models.py         # Model management and RKNN conversion
â”‚   â”œâ”€â”€ shared_data.py    # Shared data utilities
â”‚â”€â”€ rknpu/                # RKNN runtime files
â”‚   â”œâ”€â”€ librknnrt.so     # RKNN runtime library
â”‚   â”œâ”€â”€ rknn_server      # RKNN server binary
â”‚   â”œâ”€â”€ start_rknn.sh    # RKNN server startup script
â”‚â”€â”€ models/               # Downloaded and converted RKNN models
â”‚â”€â”€ main.py               # Entry point for FastAPI
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ Dockerfile            # Docker configuration
â”‚â”€â”€ .dockerignore         # Ignore unnecessary files in Docker builds
â”‚â”€â”€ README.md             # Project documentation
â”‚â”€â”€ .gitignore            # Ignore unnecessary files in Git
```

## **âš¡ Features**
âœ… FastAPI-based AI API  
âœ… RKNN optimization for Rockchip RK3588  
âœ… Automatic ONNX to RKNN conversion  
âœ… Hardware acceleration with NPU  
âœ… Dockerized for easy deployment  
âœ… Object detection with model mapping  
âœ… Direct model inference support  

## **ğŸ”§ Setup & Installation**

### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/atriva-ai/atriva-ai-rockchip.git
cd atriva-ai-rockchip
```

### **2ï¸âƒ£ Create a Virtual Environment**
```sh
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
pip install -r requirements.txt
```

### **3ï¸âƒ£ Verify NPU Hardware**
Before running the API, verify that your RKNPU hardware is working:
```sh
python3 test_rknpu.py
```

**Prerequisites:**
- Official OS image from http://www.orangepi.org was installed.
- RKNPU kernel driver must be loaded (built into kernel)
- `librknnrt.so` runtime library must be present
- RKNN toolkit2 must be installed (included in requirements.txt)

### **4ï¸âƒ£ Run the API Locally**
```sh
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```
Access the API documentation at:  
ğŸ‘‰ **http://localhost:8001/docs**

## **ğŸ³ Running with Docker**
### **1ï¸âƒ£ Build the Docker Image**
```sh
docker build -t atriva-ai-rockchip .
```

### **2ï¸âƒ£ Run the Container**
```sh
docker run -d -p 8001:8001 --name ai-rockchip-container atriva-ai-rockchip
```
Now, visit:  
ğŸ‘‰ **http://localhost:8001/docs**

## **ğŸ›  API Endpoints**

### **Object Detection**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/objects` | List available object types |
| `POST` | `/inference/detection` | Run object detection |

### **Direct Model Inference**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/models` | List available models |
| `POST` | `/inference/direct` | Run direct model inference |
| `POST` | `/model/load` | Load a specific model |

### **Camera Frame Processing**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/shared/cameras` | List available cameras |
| `GET` | `/shared/cameras/{id}/frames` | Get camera frame info |
| `POST` | `/shared/cameras/{id}/inference` | Run inference on camera frame |

## **ğŸ¯ Supported Models**

### **Object Detection Models**
- **YOLOv8n**: General object detection
- **YOLOv8n-pose**: Human pose estimation
- **YOLOv8n-obb**: Oriented bounding box detection
- **YOLOv11n**: Latest YOLO detection

### **Specialized Models**
- **RetinaFace-mobile-320**: Face detection
- **LPRNet**: License plate recognition
- **CLIP**: Image and text understanding
- **YAMNet**: Audio classification

## **ğŸ”§ Object Mapping**

The API provides user-friendly object names that map to specific models:

```python
# Object Detection (User-Friendly)
detections = run_object_detection(image, "human")      # Uses YOLOv8n
detections = run_object_detection(image, "face")       # Uses RetinaFace
detections = run_object_detection(image, "license-plate") # Uses LPRNet
detections = run_object_detection(image, "pose")       # Uses YOLOv8n-pose

# Direct Model Inference (Advanced)
output = run_inference(image, "yolov8n")              # Direct model access
output = run_inference(image, "LPRNet")               # Direct model access
```


## âœ… Verifying RKNPU Readiness on RK3588 (Orange Pi 5 / 5 Plus)

To confirm that the Rockchip NPU is enabled and ready for inference on Ubuntu images:

---

### 1. Check Kernel Driver
The RKNPU driver is usually **built into the kernel**, not a loadable module (so it will not appear in `lsmod`).

```bash
dmesg | grep -i rknpu
````

Expected output (example):

```
RKNPU fdab0000.npu: RKNPU: rknpu iommu is enabled, using iommu mode
[drm] Initialized rknpu 0.9.6 ...
```

Driver version:

```bash
sudo cat /sys/kernel/debug/rknpu/version
```

Expected:

```
RKNPU driver: v0.9.6
```

---

### 2. Verify Runtime Library

Ensure that `librknnrt.so` is installed:

```bash
ls -l /usr/lib/ | grep librknnrt
strings /usr/lib/librknnrt.so | grep "librknnrt version"
```

Expected:

```
librknnrt.so
librknnrt version: 2.3.2 (...)
```

---

### 3. Install Python API

The runtime toolkit is needed for Python testing:

```bash
pip install rknn-toolkit-lite2
```

---

### 4. Run Sanity Test

Download a sample model and test inference on the NPU:

```bash
wget https://github.com/airockchip/rknn-toolkit2/raw/master/examples/mobilenet_v1/mobilenet_v1.rknn
```

Create `test_rknpu.py`:

```python
from rknnlite.api import RKNNLite
import numpy as np

print("=== RKNN NPU Sanity Test ===")
rknn = RKNNLite()

# Load model
ret = rknn.load_rknn('mobilenet_v1.rknn')
if ret != 0:
    print("âŒ Failed to load model")
    exit(1)

# Init runtime
ret = rknn.init_runtime()
if ret != 0:
    print("âŒ Failed to init runtime")
    exit(1)

print("âœ… NPU runtime initialized")

# Run inference
dummy = np.random.randint(0, 255, (1,224,224,3), dtype=np.uint8)
outputs = rknn.inference(inputs=[dummy])
print("âœ… Inference ran successfully, output shapes:", [o.shape for o in outputs])

rknn.release()
```


### 5. **NPU Hardware Test**
Test RKNPU hardware functionality without using the API service:
```sh
python3 test_rknpu.py
```

This test will:
- âœ… Verify RKNN toolkit installation
- âœ… Check for required runtime libraries (`librknnrt.so`)
- âœ… Test RKNN API import and object creation
- âœ… Convert ONNX model to RKNN format (if needed)
- âœ… Initialize NPU runtime and verify hardware functionality
- âœ… Confirm NPU is ready for inference

**Expected Output:**
```
RKNPU Standalone Test
==================================================
=== RKNPU Hardware Test ===
âœ… librknnrt.so found
âœ… RKNN API imported successfully
âœ… RKNN object created successfully
âœ… Found ONNX model, converting to RKNN: ./models/yolov8n.onnx
âœ… RKNN configured successfully
âœ… ONNX model loaded successfully
âœ… RKNN model built successfully
âœ… NPU runtime initialized successfully
   ğŸ‰ RKNPU hardware is working!
âœ… Created dummy input data
âœ… NPU runtime is functional and ready for inference
âœ… RKNN resources released

=== Model Conversion Test ===
âœ… Found ONNX models: ['yolov8n.onnx']
âœ… RKNN conversion API available

==================================================
TEST SUMMARY:
Hardware Test: âœ… PASS
Conversion Test: âœ… PASS

ğŸ‰ All tests passed! RKNPU is ready for use.
```


### 5. Notes

* `lsmod` will **not show `rknpu`** on RK3588 because the driver is compiled into the kernel (`CONFIG_ROCKCHIP_NPU=y`).
* Check `/sys/kernel/debug/rknpu/` for driver info and stats.
* Ensure the Ubuntu image you are using includes Rockchip patches for the NPU.

---

## **ğŸ“œ License**
This project is licensed under the **MIT License**.

