
## **ğŸ“ README.md (Atriva AI API)**

```md
# Atriva AI API with RKNN for Rockchip ğŸš€

This is a FastAPI-based AI API that leverages **RKNN (Rockchip Neural Network)** for optimized deep learning inference on Rockchip hardware.  
It provides a RESTful interface for running AI models, such as object detection and image classification on RK3588 platform.

## **ğŸ“‚ Project Structure**
```plaintext
atriva-ai-rockchip/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ routes.py         # API route definitions
â”‚   â”œâ”€â”€ services.py       # AI model processing logic
â”‚   â”œâ”€â”€ models.py         # Model management and RKNN conversion
â”‚   â”œâ”€â”€ shared_data.py    # Shared data utilities
â”‚â”€â”€ rknpu/                # RKNN runtime files
â”‚   â”œâ”€â”€ librknnrt.so     # RKNN runtime library
â”‚   â”œâ”€â”€ rknn_server      # RKNN server binary
â”‚   â”œâ”€â”€ start_rknn.sh    # RKNN server startup script
â”‚â”€â”€ models/               # Downloaded and converted RKNN models
â”‚â”€â”€ main.py               # Entry point for FastAPI
â”‚â”€â”€ requirements.txt      # Python dependencies
â”‚â”€â”€ Dockerfile            # Docker configuration
â”‚â”€â”€ .dockerignore         # Ignore unnecessary files in Docker builds
â”‚â”€â”€ README.md             # Project documentation
â”‚â”€â”€ .gitignore            # Ignore unnecessary files in Git
```

## **âš¡ Features**
âœ… FastAPI-based AI API  
âœ… RKNN optimization for Rockchip RK3588  
âœ… Automatic ONNX to RKNN conversion  
âœ… Hardware acceleration with NPU  
âœ… Dockerized for easy deployment  
âœ… Object detection with model mapping  
âœ… Direct model inference support  

## **ğŸ”§ Setup & Installation**

### **1ï¸âƒ£ Clone the Repository**
```sh
git clone https://github.com/atriva-ai/atriva-ai-rockchip.git
cd atriva-ai-rockchip
```

### **2ï¸âƒ£ Create a Virtual Environment**
```sh
python3 -m venv venv
source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
pip install -r requirements.txt
```

### **3ï¸âƒ£ Run the API Locally**
```sh
uvicorn main:app --host 0.0.0.0 --port 8001 --reload
```
Access the API documentation at:  
ğŸ‘‰ **http://localhost:8001/docs**

## **ğŸ³ Running with Docker**
### **1ï¸âƒ£ Build the Docker Image**
```sh
docker build -t atriva-ai-rockchip .
```

### **2ï¸âƒ£ Run the Container**
```sh
docker run -d -p 8001:8001 --name ai-rockchip-container atriva-ai-rockchip
```
Now, visit:  
ğŸ‘‰ **http://localhost:8001/docs**

## **ğŸ›  API Endpoints**

### **Object Detection**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/objects` | List available object types |
| `POST` | `/inference/detection` | Run object detection |

### **Direct Model Inference**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/models` | List available models |
| `POST` | `/inference/direct` | Run direct model inference |
| `POST` | `/model/load` | Load a specific model |

### **Camera Frame Processing**
| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/shared/cameras` | List available cameras |
| `GET` | `/shared/cameras/{id}/frames` | Get camera frame info |
| `POST` | `/shared/cameras/{id}/inference` | Run inference on camera frame |

## **ğŸ¯ Supported Models**

### **Object Detection Models**
- **YOLOv8n**: General object detection
- **YOLOv8n-pose**: Human pose estimation
- **YOLOv8n-obb**: Oriented bounding box detection
- **YOLOv11n**: Latest YOLO detection

### **Specialized Models**
- **RetinaFace-mobile-320**: Face detection
- **LPRNet**: License plate recognition
- **CLIP**: Image and text understanding
- **YAMNet**: Audio classification

## **ğŸ”§ Object Mapping**

The API provides user-friendly object names that map to specific models:

```python
# Object Detection (User-Friendly)
detections = run_object_detection(image, "human")      # Uses YOLOv8n
detections = run_object_detection(image, "face")       # Uses RetinaFace
detections = run_object_detection(image, "license-plate") # Uses LPRNet
detections = run_object_detection(image, "pose")       # Uses YOLOv8n-pose

# Direct Model Inference (Advanced)
output = run_inference(image, "yolov8n")              # Direct model access
output = run_inference(image, "LPRNet")               # Direct model access
```

## **ğŸ§ª Running Tests**
```sh
pytest tests/
```

## **ğŸ“œ License**
This project is licensed under the **MIT License**.

